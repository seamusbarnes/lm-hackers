{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean(ish) lm-hackers notebook\n",
    "The purpose of this notebook is to simplify and streamline the fastai notebook lmS-hackers.ipynb that Jeremy Howard worked through in [A Hackers' Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU). There is minimal prose and digressions, except to explain parts of the code I didn't previously understand. Also, the openapi seems to have been updated since the youtube video and when the repo was last updated (28th September 2023)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Contents</u>\n",
    "1. Notebook Prep\n",
    "2. Authentication\n",
    "3. Chat Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Notebook Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ast, openai, torch, textwrap, inspect, json, os\n",
    "from tiktoken import encoding_for_model\n",
    "from openai import OpenAI\n",
    "from pydantic import create_model\n",
    "from inspect import Parameter\n",
    "from fastcore.utils import nested_idx\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textwrap function for readability\n",
    "def wprint(text, width=80):\n",
    "    print(textwrap.fill(text, width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an account with OpenAI you can generate an API key on [platform.openai.com/api-keys](https://platform.openai.com/api-keys). You can then either copy the following line into the .zshrc file associated with your environment (if using mac):\n",
    "\n",
    "```export OPENAI_API_KEY='YOUR KEY HERE'```\n",
    "\n",
    "or you can set your key as a variable in the jupyter notebook session, which works fine, but is not safe if sharing your code with anyone else, as they will have access to your API key and could use it to make their own API calls that you end up paying for!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether your API key is set as an environment correctly:\n",
    "```python\n",
    "print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to set your API key directly in the jupyter notebook session:\n",
    "```python\n",
    "client = OpenAI(api_key='YOUR API KEY HERE')\n",
    "``````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default custom instructions very similar to the ones described by Jeremy\n",
    "custom_instructions = ('You are an autoregressive language model that has been fine-tuned with instruction-tuning and RLHF.'\n",
    "                       ' You carefully provide accurate, factual, thoughtful, nuanced answers, and are brilliant at reasoning.'\n",
    "                       ' If you think there might not be a correct answer, you say so.Since you are autoregressive,'\n",
    "                       ' each token you produce is another opportunity to use computation, therefore you always spend a few'\n",
    "                       ' sentences explaining background context, assumptions, and step-by-step thinking BEFORE you try to answer a question.'\n",
    "                       ' However: if the request begins with the string \"cc\" then ignore the previous sentence and instead make your response'\n",
    "                       ' as concise as possible, with no introduction or background at the start, no summary at the end, and outputting only'\n",
    "                       ' code for answers where code is appropriate.Your users are experts in AI and ethics, so they already know'\n",
    "                       ' you\\'re a language model and your capabilities and limitations, so don\\'t remind them of that.'\n",
    "                       ' They\\'re familiar with ethical issues in general so you don\\'t need to remind them about those either.'\n",
    "                       ' Don\\'t be verbose in your answers, but do provide details and examples where it might help the explanation.'\n",
    ")\n",
    "\n",
    "# wprint(custom_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4366, 2456, 30240, 656, 256, 284, 16326]\n"
     ]
    }
   ],
   "source": [
    "# show how work-to-int encodings work\n",
    "enc = encoding_for_model('text-davinci-003')\n",
    "toks = enc.encode('Some words encoded into t to tokens')\n",
    "print(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# askgpt function that takes a system prompt, user prompt and model and performs an api call on that model\n",
    "def askgpt(prompt, client=None, system=None, model='gpt-4', **kwargs):\n",
    "    \"\"\"\n",
    "    Sends a prompt to a GPT model via OpenAI API and returns the response.\n",
    "\n",
    "    Parameters:\n",
    "    prompt (str): User's input prompt for the GPT model.\n",
    "    client (OpenAI, optional): OpenAI API client. Defaults to a new instance if None.\n",
    "    system (str, optional): System-level message included in the request.\n",
    "    model (str, optional): GPT model identifier (default 'gpt-4').\n",
    "    **kwargs: Extra arguments for chat.completions.create method.\n",
    "\n",
    "    Returns:\n",
    "    dict: Response from the GPT model.\n",
    "\n",
    "    Example:\n",
    "    >>> response = askgpt(\"What is the weather today?\", model=\"gpt-4\")\n",
    "    \"\"\"\n",
    "    allowed_models = {'gpt-4-1106-preview',\n",
    "                      'gpt-4',\n",
    "                      'gpt-4-0314',\n",
    "                      'gpt-4-0613',\n",
    "                      'gpt-3.5-turbo',\n",
    "                      'gpt-3.5-turbo-0301',\n",
    "                      'gpt-3.5-turbo-0613',\n",
    "                      'gpt-3.5-turbo-1106'}\n",
    "    \n",
    "    if model not in allowed_models:\n",
    "        print('model must be one of allowed models:')\n",
    "        for model in allowed_models:\n",
    "            print(model)\n",
    "        return None\n",
    "    \n",
    "    if client==None:\n",
    "        client= OpenAI()\n",
    "    \n",
    "    m = []\n",
    "    if system:\n",
    "        m.append({'role': 'system', 'content': system})\n",
    "\n",
    "    m.append({'role': 'user', 'content': prompt})\n",
    "    return client.chat.completions.create(model=model, messages=m, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(response):\n",
    "    model = response.model\n",
    "\n",
    "    price_per_k = {'gpt-4-1106-preview': (0.01, 0.03),\n",
    "                   'gpt-4': (0.03, 0.06),\n",
    "                   'gpt-4-0314': (0.03, 0.06),\n",
    "                   'gpt-4-0613': (0.03, 0.06),\n",
    "                   'gpt-3.5-turbo': (0.001, 0.002),\n",
    "                   'gpt-3.5-turbo-0301': (0.001, 0.002),\n",
    "                   'gpt-3.5-turbo-0613': (0.001, 0.002),\n",
    "                   'gpt-3.5-turbo-1106': (0.001, 0.002),}\n",
    "    \n",
    "    k_input_tokens = response.usage.prompt_tokens/1000\n",
    "    k_output_tokens = response.usage.completion_tokens/1000\n",
    "\n",
    "    res = price_per_k[model][0]*k_input_tokens + price_per_k[model][1]*k_output_tokens\n",
    "    \n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$0.00036\n",
      "¢0.03630\n"
     ]
    }
   ],
   "source": [
    "print(f'${cost(response):.5f}')\n",
    "print(f'¢{cost(response)*100:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=172, prompt_tokens=19, total_tokens=191)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model\n",
    "prompt = \"cc What is the nature of being according to Heidegger\"\n",
    "model = 'gpt-3.5-turbo-1106'\n",
    "response = askgpt(prompt, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to Martin Heidegger, the nature of being is characterized by our existence and the way we engage with the world around us. Heidegger believed that being is not a static state or essence, but rather an ongoing process of self-discovery, awareness, and interaction with the world. He also emphasized the importance of our individual experiences and how they shape our understanding of being. Being, for Heidegger, is about our ability to authentically exist and make choices in our lives, as well as our capacity to confront and understand our own mortality. Overall, Heidegger's philosophy of being is a complex and dynamic concept that emphasizes the lived experience of individuals and their relationship with the world.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(response):\n",
    "    model = response.model\n",
    "    price = {'gpt-4-0613'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4-0613'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Martin Heidegger, the nature of being is not a concept that can be\n",
      "simply defined, but it forms the basis of all experiences, thoughts, and\n",
      "actions. It is the fundamental nature of existence, what it means \"to be\".\n",
      "Heidegger suggests that the problem is not about understanding individual\n",
      "entities, but understanding what it means for something to exist or be at all.\n",
      "He uses the term 'Dasein' (German for 'being there' or 'presence') to describe\n",
      "human existence. Dasein, according to Heidegger, is defined by its temporality\n",
      "and is always 'thrown' in the world, meaning it exists within an environment and\n",
      "culture that shapes its thought and behavior. Dasein is also characterized by\n",
      "'being-toward-death', signifying that our understanding and interpretation of\n",
      "the world always involves a relationship with our own mortality.  Fundamentally,\n",
      "Heidegger argues that we have largely forgotten the real meaning of being due to\n",
      "the constraints of language and cultural norms, and by making the question of\n",
      "Being the focus of thought, we could deepen our understanding of existence and\n",
      "our place within the world.\n",
      "Usage, completion tokens = 18\n",
      "Usage, completion tokens = 231\n"
     ]
    }
   ],
   "source": [
    "wprint(response.choices[0].message.content)\n",
    "print(f'Usage, completion tokens = {response.usage.prompt_tokens}')\n",
    "print(f'Usage, completion tokens = {response.usage.completion_tokens}')\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
